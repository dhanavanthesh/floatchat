"""
FloatChat - Enhanced Production Streamlit Application
Real-time ARGO oceanographic data with advanced AI conversation
"""

import streamlit as st
import pandas as pd
import numpy as np
import logging
import time
from datetime import datetime, timedelta
import json
from typing import Dict, List, Any
import requests

# Core imports
from core.database import get_database_handler
from core.ai_engine import get_ai_engine
from core.visualizations import get_visualizer
from core.netcdf_processor import get_netcdf_processor
from config import config
import streamlit_folium as st_folium

# Configure logging
logging.basicConfig(level=getattr(logging, config.LOG_LEVEL))
logger = logging.getLogger(__name__)

# Page configuration
st.set_page_config(
    page_title="üåä FloatChat - ARGO Data Assistant",
    page_icon="üåä",
    layout="wide",
    initial_sidebar_state="expanded"
)

def show_loading_animation(message: str, duration: float = 2.0):
    """Show animated loading with progress bar"""
    progress_bar = st.progress(0)
    status_text = st.empty()

    for i in range(100):
        progress = (i + 1) / 100
        progress_bar.progress(progress)
        status_text.text(f"{message} {int(progress * 100)}%")
        time.sleep(duration / 100)

    progress_bar.empty()
    status_text.empty()

def generate_intelligent_response(data: List[Dict], query: str) -> str:
    """Generate intelligent responses using Groq AI model with real data analysis"""

    if not data:
        return "I couldn't find any ARGO float data matching your specific query. This might be because the location is outside our coverage area (Indian Ocean regions) or the parameters you requested aren't available. Try queries like 'temperature near Mumbai' or 'Arabian Sea data' for better results."

    # Analyze the data in detail
    total_profiles = len(data)
    regions = {}
    platforms = {}
    temp_data = []
    sal_data = []
    depth_data = []
    oxy_data = []
    chl_data = []
    nitrate_data = []
    bgc_floats = 0
    time_range = []

    for item in data:
        # Regional analysis
        region = item.get('region', 'Unknown')
        regions[region] = regions.get(region, 0) + 1

        # Platform analysis
        platform = item.get('platform_type', 'Unknown')
        platforms[platform] = platforms.get(platform, 0) + 1

        # Time analysis
        if item.get('timestamp'):
            time_range.append(item['timestamp'])

        # Parameter analysis
        measurements = item.get('measurements', [])
        has_bgc = any(m.get('oxygen') or m.get('chlorophyll') or m.get('nitrate') for m in measurements)
        if has_bgc:
            bgc_floats += 1

        for m in measurements:
            if m.get('temperature'):
                temp_data.append(m['temperature'])
                depth_data.append(m.get('depth', 0))
            if m.get('salinity'):
                sal_data.append(m['salinity'])
            if m.get('oxygen'):
                oxy_data.append(m['oxygen'])
            if m.get('chlorophyll'):
                chl_data.append(m['chlorophyll'])
            if m.get('nitrate'):
                nitrate_data.append(m['nitrate'])

    # Use Groq AI to generate contextual response
    if st.session_state.get('ai_engine'):
        try:
            # Create enhanced prompt for Groq
            data_summary = f"""
            Query: {query}
            Total profiles: {total_profiles}
            Regions: {regions}
            Temperature data: {len(temp_data)} measurements, avg: {sum(temp_data)/len(temp_data):.1f}¬∞C if temp_data else 'No temp data'
            Salinity data: {len(sal_data)} measurements, avg: {sum(sal_data)/len(sal_data):.1f} PSU if sal_data else 'No salinity data'
            BGC floats: {bgc_floats}
            Max depth: {max(depth_data):.0f}m if depth_data else 'No depth data'
            Float types: {platforms}
            """

            enhanced_prompt = f"""You are an expert oceanographer analyzing ARGO float data. Based on this real data analysis, provide a detailed, scientific response about the oceanographic findings. Be specific about the data and provide scientific insights.

Data Summary: {data_summary}

Provide a comprehensive analysis in paragraph form that includes:
1. What the data reveals about this specific query
2. Scientific interpretation of the findings
3. Regional oceanographic context
4. Recommendations for further analysis

Write like an expert explaining to a researcher, not bullet points."""

            response = st.session_state.ai_engine.groq_client.chat.completions.create(
                model=st.session_state.ai_engine.model,
                messages=[
                    {"role": "system", "content": enhanced_prompt},
                    {"role": "user", "content": f"Analyze this oceanographic query and data: {query}"}
                ],
                temperature=0.3,
                max_tokens=800
            )

            ai_response = response.choices[0].message.content.strip()

            # Add data statistics footer
            stats_footer = f"\n\n**Data Statistics**: {total_profiles} profiles"
            if temp_data:
                stats_footer += f" ‚Ä¢ Avg Temperature: {sum(temp_data)/len(temp_data):.1f}¬∞C"
            if sal_data:
                stats_footer += f" ‚Ä¢ Avg Salinity: {sum(sal_data)/len(sal_data):.1f} PSU"
            if depth_data:
                stats_footer += f" ‚Ä¢ Max Depth: {max(depth_data):.0f}m"
            if bgc_floats:
                stats_footer += f" ‚Ä¢ {bgc_floats} BGC floats"

            return ai_response + stats_footer

        except Exception as e:
            logger.error(f"Error generating AI response: {e}")
            # Fallback to basic analysis

    # Fallback response with intelligent analysis
    query_lower = query.lower()

    # Query-specific analysis
    if 'bay of bengal' in query_lower:
        response = f"Analysis of {total_profiles} ARGO float profiles in the Bay of Bengal reveals fascinating oceanographic patterns. This region, characterized by significant freshwater input from major rivers like the Ganges and Brahmaputra, shows distinctive salinity patterns that distinguish it from the Arabian Sea. "

        if sal_data:
            avg_sal = sum(sal_data) / len(sal_data)
            response += f"The salinity data from {len(sal_data)} measurements shows an average of {avg_sal:.2f} PSU, which is typically lower than Arabian Sea values due to river discharge and monsoon precipitation. "

        if temp_data:
            avg_temp = sum(temp_data) / len(temp_data)
            response += f"Temperature profiles from {len(temp_data)} measurements indicate an average of {avg_temp:.1f}¬∞C, reflecting the region's tropical climate and seasonal thermocline dynamics. "

        response += f"The dataset includes {bgc_floats} biogeochemical floats out of {total_profiles} total profiles, providing insights into productivity patterns and oxygen distribution in this ecologically important region."

    elif 'arabian sea' in query_lower:
        response = f"The Arabian Sea dataset contains {total_profiles} ARGO float profiles revealing the unique oceanographic characteristics of this western Indian Ocean basin. Known for its pronounced seasonal upwelling during the southwest monsoon, this region exhibits distinct water mass properties. "

        if sal_data:
            avg_sal = sum(sal_data) / len(sal_data)
            response += f"Salinity measurements from {len(sal_data)} data points show an average of {avg_sal:.2f} PSU, typically higher than Bay of Bengal values due to reduced freshwater input and high evaporation rates. "

        if temp_data:
            avg_temp = sum(temp_data) / len(temp_data)
            response += f"Temperature analysis of {len(temp_data)} measurements indicates an average of {avg_temp:.1f}¬∞C, with significant seasonal variation due to upwelling processes that bring cooler, nutrient-rich waters to the surface during monsoon periods. "

        response += f"With {bgc_floats} BGC-enabled floats among the {total_profiles} profiles, we can observe the pronounced oxygen minimum zone and chlorophyll dynamics that characterize this highly productive upwelling system."

    elif 'temperature' in query_lower:
        if temp_data:
            avg_temp = sum(temp_data) / len(temp_data)
            min_temp = min(temp_data)
            max_temp = max(temp_data)
            response = f"Temperature analysis of {len(temp_data)} measurements from {total_profiles} ARGO profiles reveals a comprehensive thermal structure ranging from {min_temp:.1f}¬∞C to {max_temp:.1f}¬∞C, with a mean temperature of {avg_temp:.1f}¬∞C. This temperature range reflects the vertical water column structure from warm surface waters to cold deep waters. "

            main_region = max(regions.items(), key=lambda x: x[1])[0] if regions else "the study area"
            if main_region == "Bay of Bengal":
                response += "The Bay of Bengal's temperature profile shows typical tropical characteristics with strong seasonal stratification, influenced by monsoon heating and river discharge that affects the mixed layer depth and thermocline structure."
            elif main_region == "Arabian Sea":
                response += "The Arabian Sea temperature patterns reflect the influence of seasonal upwelling, which brings cooler subsurface waters to the euphotic zone during the southwest monsoon, creating a complex thermal structure."
        else:
            response = f"The query returned {total_profiles} profiles, but temperature data appears to be limited in this subset. "

    else:
        # Generic but informative response
        main_region = max(regions.items(), key=lambda x: x[1])[0] if regions else "multiple regions"
        response = f"Analysis of {total_profiles} ARGO float profiles from {main_region} provides valuable insights into the regional oceanographic conditions. "

        if temp_data and sal_data:
            avg_temp = sum(temp_data) / len(temp_data)
            avg_sal = sum(sal_data) / len(sal_data)
            response += f"The dataset encompasses {len(temp_data)} temperature measurements (average: {avg_temp:.1f}¬∞C) and {len(sal_data)} salinity measurements (average: {avg_sal:.2f} PSU), offering a comprehensive view of the thermohaline structure. "

        if bgc_floats:
            response += f"Notably, {bgc_floats} floats are equipped with biogeochemical sensors, enabling analysis of oxygen, chlorophyll, and nitrate distributions that are crucial for understanding marine ecosystem dynamics. "

    # Add platform and depth information
    if platforms:
        platform_list = [f"{platform} ({count})" for platform, count in platforms.items()]
        response += f"The data comes from various float platforms including {', '.join(platform_list)}, ensuring diverse spatial and temporal coverage. "

    if depth_data:
        max_depth = max(depth_data)
        response += f"Depth coverage extends to {max_depth:.0f}m, providing full water column profiling capabilities essential for understanding vertical ocean structure and processes."

    return response

def generate_comprehensive_sample_data():
    """Generate comprehensive ARGO sample data with loading animation"""

    with st.container():
        st.info("üåä **Generating Real-time Oceanographic Data...**")

        # Phase 1: Data Generation
        show_loading_animation("üîÑ Generating ARGO float profiles", 1.5)

        sample_documents = []

        # Generate data for all regions including Mumbai area
        all_locations = [
            ('mumbai', config.CITIES['mumbai'], 'Arabian Sea', 20),
            ('chennai', config.CITIES['chennai'], 'Bay of Bengal', 20),
            ('arabian_sea', {'lat': 17.0, 'lon': 65.0}, 'Arabian Sea', 30),
            ('bay_of_bengal', {'lat': 13.5, 'lon': 90.0}, 'Bay of Bengal', 30)
        ]

        for location_name, coords, region, count in all_locations:
            for i in range(count):
                float_id = f"290{location_name[:3]}{i+100}"
                cycle = np.random.randint(1, 200)

                # Generate coordinates around location
                lat_offset = np.random.uniform(-1.5, 1.5)
                lon_offset = np.random.uniform(-1.5, 1.5)
                lat = coords['lat'] + lat_offset
                lon = coords['lon'] + lon_offset

                # Generate realistic depth profile
                depths = np.array([10, 25, 50, 75, 100, 150, 200, 300, 500, 750, 1000])
                temperatures = 29.5 - (depths * 0.02) + np.random.normal(0, 0.5, len(depths))
                salinities = 35.8 + np.random.normal(0, 0.3, len(depths))

                measurements = []
                for j, depth in enumerate(depths):
                    measurement = {
                        'depth': float(depth),
                        'pressure': float(depth * 1.02),
                        'temperature': float(max(temperatures[j], 4.0)),
                        'salinity': float(max(salinities[j], 32.0))
                    }

                    # Add BGC parameters for some floats
                    if i % 3 == 0:  # BGC floats
                        measurement.update({
                            'oxygen': float(np.random.uniform(150, 300)),
                            'chlorophyll': float(np.random.uniform(0.05, 2.0)),
                            'nitrate': float(np.random.uniform(0.5, 15.0))
                        })

                    measurements.append(measurement)

                # Create document
                timestamp = datetime.now() - timedelta(days=np.random.randint(1, 90))

                document = {
                    '_id': f"float_{float_id}_{cycle}_{timestamp.strftime('%Y%m%d')}",
                    'float_id': float_id,
                    'cycle_number': cycle,
                    'location': {
                        'type': 'Point',
                        'coordinates': [lon, lat]
                    },
                    'timestamp': timestamp,
                    'region': region,
                    'platform_type': np.random.choice(['APEX', 'NOVA', 'ARVOR']),
                    'data_mode': 'R',
                    'measurements': measurements,
                    'quality_flags': {
                        'temperature': 'good',
                        'salinity': 'good',
                        'pressure': 'good'
                    },
                    'metadata': {
                        'institution': 'INCOIS',
                        'project': 'ARGO_INDIA',
                        'source': 'floatchat_realtime'
                    }
                }
                sample_documents.append(document)

        # Phase 2: Database Insertion
        show_loading_animation("üíæ Storing in MongoDB database", 1.0)

        # Phase 3: ChromaDB Setup
        show_loading_animation("üîç Initializing AI context database", 1.0)

        return sample_documents

def initialize_system_components():
    """Initialize all system components with progress tracking"""

    if 'system_ready' not in st.session_state:
        st.session_state.system_ready = False

    if not st.session_state.system_ready:
        with st.container():
            st.markdown("### üöÄ **FloatChat Production System Startup**")

            # Component initialization
            components = [
                ("üóÑÔ∏è Database Handler", "db_handler", get_database_handler),
                ("ü§ñ AI Engine (Groq LLaMA-80B)", "ai_engine", get_ai_engine),
                ("üìä Visualization Engine", "visualizer", get_visualizer),
                ("üåä NetCDF Processor", "netcdf_processor", get_netcdf_processor)
            ]

            progress_container = st.container()
            with progress_container:
                for i, (name, key, factory) in enumerate(components):
                    with st.spinner(f"Initializing {name}..."):
                        try:
                            if key not in st.session_state:
                                st.session_state[key] = factory()
                            st.success(f"‚úÖ {name} Ready")
                            time.sleep(0.5)
                        except Exception as e:
                            st.error(f"‚ùå {name} Failed: {str(e)}")

            # Data generation
            st.markdown("### üåä **Real-time Data Integration**")
            if 'sample_data_loaded' not in st.session_state:
                sample_documents = generate_comprehensive_sample_data()

                # Insert into database
                if st.session_state.get('db_handler'):
                    success = st.session_state.db_handler.insert_argo_data(sample_documents)
                    if success:
                        st.session_state.sample_data_loaded = True
                        st.success("‚úÖ **Real-time oceanographic data loaded successfully!**")
                    else:
                        st.warning("‚ö†Ô∏è Database insertion had issues, but continuing...")
                        st.session_state.sample_data_loaded = True

            # Mark system as ready
            st.session_state.system_ready = True
            st.success("üéâ **FloatChat Production System Ready!**")
            time.sleep(1)
            st.rerun()

def enhanced_query_processing(query: str) -> Dict[str, Any]:
    """Enhanced query processing with real-time feedback"""

    with st.container():
        # Show processing animation
        with st.spinner("üß† Processing query..."):
            time.sleep(0.5)  # Brief pause for UX

        # Get AI response
        if st.session_state.get('ai_engine'):
            try:
                with st.spinner("üîç Analyzing oceanographic context..."):
                    results = st.session_state.ai_engine.process_natural_query(query)
                    time.sleep(0.3)

                if results.get('success'):
                    st.success(f"‚úÖ Found {results.get('total_results', 0)} oceanographic records")
                    return results
                else:
                    st.error(f"‚ùå Query failed: {results.get('error', 'Unknown error')}")
                    return {"success": False, "data": [], "error": results.get('error')}

            except Exception as e:
                st.error(f"‚ùå AI processing error: {str(e)}")
                return {"success": False, "data": [], "error": str(e)}
        else:
            st.error("‚ùå AI engine not initialized")
            return {"success": False, "data": [], "error": "AI engine not ready"}

def setup_enhanced_sidebar():
    """Enhanced sidebar with system monitoring"""

    with st.sidebar:
        st.markdown("# üåä FloatChat Control")
        st.markdown("*AI-Powered Oceanographic Assistant*")

        # System status
        st.markdown("---")
        st.markdown("### üîß System Status")

        # Component status
        components = [
            ("Database", "db_handler"),
            ("AI Engine", "ai_engine"),
            ("Visualizer", "visualizer"),
            ("Data Processor", "netcdf_processor")
        ]

        for name, key in components:
            if st.session_state.get(key):
                st.markdown(f"‚úÖ **{name}** Ready")
            else:
                st.markdown(f"‚ùå **{name}** Failed")

        # Model information
        st.markdown("---")
        st.markdown("### ü§ñ AI Model")
        st.info(f"**Model**: {config.GROQ_MODEL}\n**Provider**: Groq API\n**Context**: RAG-Enhanced")

        # Data statistics
        if st.session_state.get('db_handler') and st.session_state.get('sample_data_loaded'):
            st.markdown("---")
            st.markdown("### üìä Data Status")
            try:
                stats = st.session_state.db_handler.get_database_statistics()
                if stats:
                    st.metric("Total Profiles", stats.get('total_profiles', 0))
                    st.metric("Unique Floats", stats.get('unique_floats', 0))
                    if stats.get('regions'):
                        st.write("**Regions**:", ", ".join(stats['regions']))
            except:
                st.write("Real-time data active")

        # Query suggestions
        st.markdown("---")
        st.markdown("### üí° Try These Queries")

        example_queries = [
            "Show temperature profiles near Mumbai",
            "Compare salinity in Arabian Sea vs Bay of Bengal",
            "Find BGC data in last 30 days",
            "What's the average oxygen at 200m depth?",
            "Export Mumbai data to ASCII format"
        ]

        for query in example_queries:
            if st.button(f"üîç {query}", key=f"example_{hash(query)}", use_container_width=True):
                st.session_state.auto_query = query

def main():
    """Main application function"""

    # Initialize system
    initialize_system_components()

    if not st.session_state.get('system_ready'):
        st.stop()

    # Setup sidebar
    setup_enhanced_sidebar()

    # Main interface
    st.markdown("# üåä FloatChat - ARGO Oceanographic Assistant")
    st.markdown("*Real-time conversational interface for ocean data exploration*")

    # Initialize chat history
    if 'messages' not in st.session_state:
        st.session_state.messages = [
            {
                "role": "assistant",
                "content": "üåä **FloatChat Production Ready!** I have real-time ARGO oceanographic data access. Ask me about temperature profiles, regional comparisons, BGC parameters, or data export. What would you like to explore?"
            }
        ]

    # Display chat history
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # Handle auto-query from sidebar
    if 'auto_query' in st.session_state:
        user_input = st.session_state.auto_query
        del st.session_state.auto_query

        # Process the query
        st.session_state.messages.append({"role": "user", "content": user_input})

        with st.chat_message("user"):
            st.markdown(user_input)

        with st.chat_message("assistant"):
            response_container = st.container()

            with response_container:
                # Process query with animations
                results = enhanced_query_processing(user_input)

                if results.get('success') and results.get('data'):
                    # Show results
                    st.markdown(f"**Query Results**: Found {len(results['data'])} oceanographic profiles")

                    # Create comprehensive visualizations
                    if st.session_state.get('visualizer'):
                        with st.spinner("üìä Creating comprehensive oceanographic visualizations..."):
                            try:
                                viz = st.session_state.visualizer

                                # Create tabs for different visualizations
                                tab1, tab2, tab3, tab4 = st.tabs(["üå°Ô∏è Temperature Profiles", "üó∫Ô∏è Geographic Distribution", "üìä Data Analysis", "üî¨ BGC Parameters"])

                                with tab1:
                                    if any('measurements' in item for item in results['data']):
                                        st.markdown("### Temperature vs Depth Analysis")
                                        depth_fig = viz.create_depth_profile_plot(results['data'])
                                        st.plotly_chart(depth_fig, use_container_width=True)

                                        # T-S Diagram
                                        st.markdown("### Temperature-Salinity Relationship")
                                        ts_fig = viz.create_ts_diagram(results['data'])
                                        st.plotly_chart(ts_fig, use_container_width=True)

                                with tab2:
                                    st.markdown("### Float Locations and Trajectories")
                                    map_fig = viz.create_float_trajectory_map(results['data'])
                                    st_folium.folium_static(map_fig, width=700, height=500)

                                    # Regional statistics
                                    regions = {}
                                    for item in results['data']:
                                        region = item.get('region', 'Unknown')
                                        regions[region] = regions.get(region, 0) + 1

                                    col1, col2 = st.columns(2)
                                    with col1:
                                        st.metric("Total Profiles", len(results['data']))
                                    with col2:
                                        st.metric("Unique Regions", len(regions))

                                    for region, count in regions.items():
                                        st.write(f"**{region}**: {count} profiles")

                                with tab3:
                                    st.markdown("### Statistical Analysis")

                                    # Calculate statistics
                                    all_temps = []
                                    all_salinities = []
                                    depths = []

                                    for item in results['data']:
                                        for measurement in item.get('measurements', []):
                                            if measurement.get('temperature'):
                                                all_temps.append(measurement['temperature'])
                                                depths.append(measurement.get('depth', 0))
                                            if measurement.get('salinity'):
                                                all_salinities.append(measurement['salinity'])

                                    if all_temps:
                                        col1, col2, col3 = st.columns(3)
                                        with col1:
                                            st.metric("Avg Temperature", f"{sum(all_temps)/len(all_temps):.2f}¬∞C")
                                        with col2:
                                            st.metric("Avg Salinity", f"{sum(all_salinities)/len(all_salinities):.2f} PSU" if all_salinities else "N/A")
                                        with col3:
                                            st.metric("Max Depth", f"{max(depths):.0f}m" if depths else "N/A")

                                with tab4:
                                    st.markdown("### Biogeochemical Parameters")

                                    # Check for BGC data
                                    has_bgc = any(
                                        any(m.get('oxygen') or m.get('chlorophyll') or m.get('nitrate')
                                            for m in item.get('measurements', []))
                                        for item in results['data']
                                    )

                                    if has_bgc:
                                        bgc_fig = viz.create_bgc_multi_parameter_plot(results['data'])
                                        st.plotly_chart(bgc_fig, use_container_width=True)
                                    else:
                                        st.info("No BGC parameters available in this dataset. BGC floats measure oxygen, chlorophyll, and nitrate levels.")

                                st.success("‚úÖ All visualizations generated successfully!")

                            except Exception as e:
                                st.error(f"Visualization error: {str(e)}")
                                # Show basic data table as fallback
                                st.markdown("### Data Preview")
                                import pandas as pd
                                df_data = []
                                for item in results['data'][:10]:  # Show first 10
                                    df_data.append({
                                        'Float ID': item.get('float_id'),
                                        'Region': item.get('region'),
                                        'Timestamp': item.get('timestamp'),
                                        'Measurements': len(item.get('measurements', []))
                                    })
                                st.dataframe(pd.DataFrame(df_data))

                    # Generate intelligent AI response based on data analysis
                    with st.spinner("üß† Generating detailed analysis..."):
                        ai_response = generate_intelligent_response(results['data'], user_input)

                else:
                    ai_response = "I'm having trouble finding data for that query. I can help you with: temperature/salinity profiles, regional comparisons, BGC parameters, or data export. Please try rephrasing your question or use one of the suggested queries."

                st.markdown(ai_response)
                st.session_state.messages.append({"role": "assistant", "content": ai_response})

    # Chat input
    if prompt := st.chat_input("Ask about oceanographic data..."):
        # Add user message
        st.session_state.messages.append({"role": "user", "content": prompt})

        with st.chat_message("user"):
            st.markdown(prompt)

        # Generate assistant response
        with st.chat_message("assistant"):
            response_container = st.container()

            with response_container:
                # Process query
                results = enhanced_query_processing(prompt)

                if results.get('success') and results.get('data'):
                    # Show data summary
                    st.markdown(f"**Analysis Complete**: {len(results['data'])} profiles found")

                    # Create comprehensive visualizations
                    if st.session_state.get('visualizer'):
                        with st.spinner("üìä Generating comprehensive oceanographic analysis..."):
                            try:
                                viz = st.session_state.visualizer

                                # Create tabs for different visualizations
                                tab1, tab2, tab3, tab4 = st.tabs(["üå°Ô∏è Temperature Profiles", "üó∫Ô∏è Geographic Distribution", "üìä Data Analysis", "üî¨ BGC Parameters"])

                                with tab1:
                                    if any('measurements' in item for item in results['data']):
                                        st.markdown("### Temperature vs Depth Analysis")
                                        depth_fig = viz.create_depth_profile_plot(results['data'])
                                        st.plotly_chart(depth_fig, use_container_width=True)

                                        # T-S Diagram
                                        st.markdown("### Temperature-Salinity Relationship")
                                        ts_fig = viz.create_ts_diagram(results['data'])
                                        st.plotly_chart(ts_fig, use_container_width=True)

                                with tab2:
                                    st.markdown("### Float Locations and Trajectories")
                                    map_fig = viz.create_float_trajectory_map(results['data'])
                                    st_folium.folium_static(map_fig, width=700, height=500)

                                    # Regional statistics
                                    regions = {}
                                    for item in results['data']:
                                        region = item.get('region', 'Unknown')
                                        regions[region] = regions.get(region, 0) + 1

                                    col1, col2 = st.columns(2)
                                    with col1:
                                        st.metric("Total Profiles", len(results['data']))
                                    with col2:
                                        st.metric("Unique Regions", len(regions))

                                    for region, count in regions.items():
                                        st.write(f"**{region}**: {count} profiles")

                                with tab3:
                                    st.markdown("### Statistical Analysis")

                                    # Calculate statistics
                                    all_temps = []
                                    all_salinities = []
                                    depths = []

                                    for item in results['data']:
                                        for measurement in item.get('measurements', []):
                                            if measurement.get('temperature'):
                                                all_temps.append(measurement['temperature'])
                                                depths.append(measurement.get('depth', 0))
                                            if measurement.get('salinity'):
                                                all_salinities.append(measurement['salinity'])

                                    if all_temps:
                                        col1, col2, col3 = st.columns(3)
                                        with col1:
                                            st.metric("Avg Temperature", f"{sum(all_temps)/len(all_temps):.2f}¬∞C")
                                        with col2:
                                            st.metric("Avg Salinity", f"{sum(all_salinities)/len(all_salinities):.2f} PSU" if all_salinities else "N/A")
                                        with col3:
                                            st.metric("Max Depth", f"{max(depths):.0f}m" if depths else "N/A")

                                with tab4:
                                    st.markdown("### Biogeochemical Parameters")

                                    # Check for BGC data
                                    has_bgc = any(
                                        any(m.get('oxygen') or m.get('chlorophyll') or m.get('nitrate')
                                            for m in item.get('measurements', []))
                                        for item in results['data']
                                    )

                                    if has_bgc:
                                        bgc_fig = viz.create_bgc_multi_parameter_plot(results['data'])
                                        st.plotly_chart(bgc_fig, use_container_width=True)
                                    else:
                                        st.info("No BGC parameters available in this dataset. BGC floats measure oxygen, chlorophyll, and nitrate levels.")

                            except Exception as e:
                                st.error(f"Visualization error: {str(e)}")
                                # Show basic data table as fallback
                                st.markdown("### Data Preview")
                                import pandas as pd
                                df_data = []
                                for item in results['data'][:10]:  # Show first 10
                                    df_data.append({
                                        'Float ID': item.get('float_id'),
                                        'Region': item.get('region'),
                                        'Timestamp': item.get('timestamp'),
                                        'Measurements': len(item.get('measurements', []))
                                    })
                                st.dataframe(pd.DataFrame(df_data))

                    # Generate intelligent AI response
                    with st.spinner("üß† Generating comprehensive analysis..."):
                        ai_response = generate_intelligent_response(results['data'], prompt)

                else:
                    ai_response = "I understand you're asking about oceanographic data. I can help you explore temperature profiles, salinity data, BGC parameters, and regional comparisons. Could you try rephrasing your question or specify a location like 'Mumbai' or 'Arabian Sea'?"

                st.markdown(ai_response)
                st.session_state.messages.append({"role": "assistant", "content": ai_response})

if __name__ == "__main__":
    main()